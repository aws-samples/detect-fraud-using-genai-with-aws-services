{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ca7f9a-8a56-47cb-b5de-7b3775bc0f29",
   "metadata": {},
   "source": [
    "# Training an image classifier to detect AI generated images\n",
    "\n",
    "Based on the research here: https://arxiv.org/pdf/2303.14126v1.pdf\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\n",
    "\n",
    "Dataset attribution:\n",
    "\n",
    "Krizhevsky, A., & Hinton, G. (2009). Learning multiple layers of features from tiny images.\n",
    "\n",
    "Bird, J.J. and Lotfi, A., 2024. CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images. IEEE Access.\n",
    "\n",
    "Real images are from Krizhevsky & Hinton (2009), fake images are from Bird & Lotfi (2024). The Bird & Lotfi study is available here https://ieeexplore.ieee.org/abstract/document/10409290 \n",
    "\n",
    "# Pre-Requisite Activities\n",
    "\n",
    "NOTE: If you are running this Notebook on an ARM device, it must be built from source as per this Github issue: https://github.com/apache/mxnet/issues/19234#issuecomment-699571539\n",
    "\n",
    "Step 1: Download the dataaset from https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\n",
    "\n",
    "Step 2: Unzip dataset into /data folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b494595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d738335-02c8-411c-845f-2de51ce3375f",
   "metadata": {},
   "source": [
    "## Install pre-requisites and convert dataset to RecordIO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db187f-64f6-4df4-baa6-110f7ef39864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "!python im2rec.py data/train.lst data/train --recursive --list --num-thread 8\n",
    "!python im2rec.py data/test.lst data/test --recursive --list --num-thread 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef25a7-bda8-4c01-8f1e-2b46d6ffc962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python im2rec.py data/train.lst data/train --recursive --pass-through --pack-label --num-thread 8\n",
    "!python im2rec.py data/test.lst data/test --recursive --pass-through --pack-label --num-thread 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353bc737-8c14-4c14-acab-333e41bf6f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker,os\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "training_image = get_image_uri(sagemaker_session.boto_region_name, 'image-classification', repo_version=\"latest\")\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket() \n",
    "prefix = \"dataset\"\n",
    "\n",
    "s3_client.upload_file(\"data/train.lst.rec\", bucket_name, \"dataset/train.rec\")\n",
    "s3_client.upload_file(\"data/test.lst.rec\", bucket_name, \"dataset/test.rec\")\n",
    "\n",
    "print('Uploaded dataset files to S3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314b36d-b39d-47b9-b484-af17c3df14a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Image Classifier\n",
    "\n",
    "NOTE: This could take a few hours to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934ccb4-6f71-4b6e-95dd-6db17358a8e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_files_in_directory(directory):\n",
    "    count = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        count += len(filenames)\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "s3_train_data = 's3://{}/{}/train.rec'.format(bucket_name,prefix)\n",
    "s3_validation_data = 's3://{}/{}/test.rec'.format(bucket_name,prefix)\n",
    "s3_output_location = 's3://{}/output'.format(bucket_name)\n",
    "\n",
    "image_classifier = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p2.xlarge',\n",
    "    volume_size=50,\n",
    "    max_run=360000,\n",
    "    input_mode='File',\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Set hyperparameters\n",
    "image_classifier.set_hyperparameters(\n",
    "    num_layers=50,\n",
    "    image_shape=\"3,32,32\",\n",
    "    num_classes=2,\n",
    "    num_training_samples=count_files_in_directory('data/train'),\n",
    "    epochs=10,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "# Create data channels\n",
    "train_data = sagemaker.inputs.TrainingInput(s3_train_data, content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.inputs.TrainingInput(s3_validation_data, content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "data_channels = {'train': train_data, 'validation': validation_data}\n",
    "\n",
    "# Train\n",
    "image_classifier.fit(inputs=data_channels, logs=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d4198-0d15-4fe6-b5e2-18ec24d1c3a3",
   "metadata": {},
   "source": [
    "## Create Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91aea76-c662-4026-9fad-5205b5793109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = image_classifier.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "\n",
    "print('Sagemaker Endpoint deployed', predictor.endpoint_name)\n",
    "\n",
    "print('Placing the Sagemaker Endpoint name in the SSM Parameter /fraud-detection/sagemaker/endpoint/name')\n",
    "\n",
    "ssm_client = boto3.client('ssm')\n",
    "\n",
    "parameter_name = '/fraud-detection/sagemaker/endpoint/name'\n",
    "\n",
    "\n",
    "# Write the parameter value to SSM\n",
    "ssm_client.put_parameter(\n",
    "    Name=parameter_name,\n",
    "    Value=predictor.endpoint_name,\n",
    "    Type='String',\n",
    "    Overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7e3d2d-5dd6-4568-9c25-8b1ac696462c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b768d4-d29c-4766-a542-9ab939964677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    # Load and resize the image using PIL\n",
    "    with Image.open(image_path) as img:\n",
    "        img_resized = img.resize((32, 32))\n",
    "        \n",
    "    # Convert to numpy array and normalize\n",
    "    img_array = np.array(img_resized)\n",
    "    img_array = img_array.astype(np.float32) / 255\n",
    "\n",
    "    # Change the shape of the array to CHW from HWC\n",
    "    img_array = np.transpose(img_array, (2, 0, 1))\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Convert to byte stream\n",
    "    img_byte_stream = io.BytesIO()\n",
    "    np.save(img_byte_stream, img_array)\n",
    "    \n",
    "    return img_byte_stream.getvalue()\n",
    "\n",
    "image_path = 'laptop-generated.png'\n",
    "image_payload = load_and_preprocess_image(image_path)\n",
    "\n",
    "response = predictor.predict(image_payload)\n",
    "\n",
    "probabilities = response['predictions'][0]['probabilities']\n",
    "predicted_class = np.argmax(probabilities)\n",
    "\n",
    "labels = ['REAL', 'FAKE']\n",
    "print(f\"Predicted class: {labels[predicted_class]} with probability: {probabilities[predicted_class]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
